



<!DOCTYPE html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="PyTorch 0.3.0 中文文档">
      
      
        <link rel="canonical" href="http://pytorch.apachecn.org/62/">
      
      
        <meta name="author" content="ApacheCN Team">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.0.3">
    
    
      
        <title>Distributed communication package - torch.distributed - PyTorch 0.3.0 中文文档</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.451f80e5.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#ff7043">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    

    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
        }
    });
    </script>
    
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    
    <!-- google webmaster -->
    <meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo" />
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="../#distributed-communication-package-torchdistributed" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="http://pytorch.apachecn.org" title="PyTorch 0.3.0 中文文档" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                PyTorch 0.3.0 中文文档
              </span>
              <span class="md-header-nav__topic">
                Distributed communication package - torch.distributed
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/apachecn/pytorch-doc-zh/" title="前往 Github 仓库" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      pytorch-doc-zh
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href=".." title="主页" class="md-tabs__link">
          主页
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../0/" title="中文教程" class="md-tabs__link">
          中文教程
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../45/" title="中文文档" class="md-tabs__link md-tabs__link--active">
          中文文档
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="http://pytorch.apachecn.org" title="PyTorch 0.3.0 中文文档" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    PyTorch 0.3.0 中文文档
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/apachecn/pytorch-doc-zh/" title="前往 Github 仓库" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      pytorch-doc-zh
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      主页
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        主页
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href=".." title="主页" class="md-nav__link">
      主页
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      中文教程
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        中文教程
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../0/" title="初学者教程" class="md-nav__link">
      初学者教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../1/" title="PyTorch 深度学习: 60 分钟极速入门教程" class="md-nav__link">
      PyTorch 深度学习: 60 分钟极速入门教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2/" title="PyTorch 是什么？" class="md-nav__link">
      PyTorch 是什么？
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3/" title="自动求导: 自动微分" class="md-nav__link">
      自动求导: 自动微分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../4/" title="神经网络" class="md-nav__link">
      神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../5/" title="训练一个分类器" class="md-nav__link">
      训练一个分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../6/" title="可选: 数据并行" class="md-nav__link">
      可选: 数据并行
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../7/" title="PyTorch for former Torch users" class="md-nav__link">
      PyTorch for former Torch users
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../8/" title="Tensors" class="md-nav__link">
      Tensors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../9/" title="Autograd (自动求导)" class="md-nav__link">
      Autograd (自动求导)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../10/" title="nn package" class="md-nav__link">
      nn package
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../11/" title="Multi-GPU examples" class="md-nav__link">
      Multi-GPU examples
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../12/" title="跟着例子学习 PyTorch" class="md-nav__link">
      跟着例子学习 PyTorch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../13/" title="Warm-up: numpy" class="md-nav__link">
      Warm-up: numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../14/" title="PyTorch: Tensors" class="md-nav__link">
      PyTorch: Tensors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../15/" title="PyTorch: 变量和autograd" class="md-nav__link">
      PyTorch: 变量和autograd
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../16/" title="PyTorch: 定义新的autograd函数" class="md-nav__link">
      PyTorch: 定义新的autograd函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../17/" title="TensorFlow: 静态图" class="md-nav__link">
      TensorFlow: 静态图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../18/" title="PyTorch: nn包" class="md-nav__link">
      PyTorch: nn包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../19/" title="PyTorch: optim包" class="md-nav__link">
      PyTorch: optim包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../20/" title="PyTorch: 定制化nn模块" class="md-nav__link">
      PyTorch: 定制化nn模块
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../21/" title="PyTorch: 动态控制流程 + 权重共享" class="md-nav__link">
      PyTorch: 动态控制流程 + 权重共享
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../22/" title="迁移学习教程" class="md-nav__link">
      迁移学习教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../23/" title="数据加载和处理教程" class="md-nav__link">
      数据加载和处理教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../24/" title="针对NLP的Pytorch深度学习" class="md-nav__link">
      针对NLP的Pytorch深度学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../25/" title="PyTorch介绍" class="md-nav__link">
      PyTorch介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../26/" title="PyTorch深度学习" class="md-nav__link">
      PyTorch深度学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../27/" title="词汇嵌入:编码词汇语义" class="md-nav__link">
      词汇嵌入:编码词汇语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../28/" title="序列模型和 LSTM 网络（长短记忆网络）" class="md-nav__link">
      序列模型和 LSTM 网络（长短记忆网络）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../29/" title="高级教程: 作出动态决策和 Bi-LSTM CRF" class="md-nav__link">
      高级教程: 作出动态决策和 Bi-LSTM CRF
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../30/" title="中级教程" class="md-nav__link">
      中级教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../31/" title="用字符级RNN分类名称" class="md-nav__link">
      用字符级RNN分类名称
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../32/" title="基与字符级RNN（Char-RNN）的人名生成" class="md-nav__link">
      基与字符级RNN（Char-RNN）的人名生成
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../33/" title="用基于注意力机制的seq2seq神经网络进行翻译" class="md-nav__link">
      用基于注意力机制的seq2seq神经网络进行翻译
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../34/" title="强化学习（DQN）教程" class="md-nav__link">
      强化学习（DQN）教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../35/" title="Writing Distributed Applications with PyTorch" class="md-nav__link">
      Writing Distributed Applications with PyTorch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../36/" title="空间转换网络 (Spatial Transformer Networks) 教程" class="md-nav__link">
      空间转换网络 (Spatial Transformer Networks) 教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../37/" title="高级教程" class="md-nav__link">
      高级教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../38/" title="用 PyTorch 做 神经转换 (Neural Transfer)" class="md-nav__link">
      用 PyTorch 做 神经转换 (Neural Transfer)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../39/" title="使用 numpy 和 scipy 创建扩展" class="md-nav__link">
      使用 numpy 和 scipy 创建扩展
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../40/" title="使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile" class="md-nav__link">
      使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../41/" title="为 pytorch 自定义 C 扩展" class="md-nav__link">
      为 pytorch 自定义 C 扩展
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../42/" title="项目相关" class="md-nav__link">
      项目相关
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../43/" title="项目贡献者" class="md-nav__link">
      项目贡献者
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../44/" title="组织学习交流群" class="md-nav__link">
      组织学习交流群
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      中文文档
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        中文文档
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../45/" title="介绍" class="md-nav__link">
      介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../46/" title="自动求导机制" class="md-nav__link">
      自动求导机制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../47/" title="广播语义" class="md-nav__link">
      广播语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../48/" title="CUDA 语义" class="md-nav__link">
      CUDA 语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../49/" title="扩展 PyTorch" class="md-nav__link">
      扩展 PyTorch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../50/" title="多进程的最佳实践" class="md-nav__link">
      多进程的最佳实践
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../51/" title="序列化语义" class="md-nav__link">
      序列化语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../52/" title="Package 参考" class="md-nav__link">
      Package 参考
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../53/" title="torch" class="md-nav__link">
      torch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../54/" title="torch.Tensor" class="md-nav__link">
      torch.Tensor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../55/" title="torch.sparse" class="md-nav__link">
      torch.sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../56/" title="torch.Storage" class="md-nav__link">
      torch.Storage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../57/" title="torch.nn" class="md-nav__link">
      torch.nn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../58/" title="torch.optim" class="md-nav__link">
      torch.optim
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../59/" title="Automatic differentiation package - torch.autograd" class="md-nav__link">
      Automatic differentiation package - torch.autograd
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../60/" title="Probability distributions - torch.distributions" class="md-nav__link">
      Probability distributions - torch.distributions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../61/" title="Multiprocessing package - torch.multiprocessing" class="md-nav__link">
      Multiprocessing package - torch.multiprocessing
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Distributed communication package - torch.distributed
      </label>
    
    <a href="./" title="Distributed communication package - torch.distributed" class="md-nav__link md-nav__link--active">
      Distributed communication package - torch.distributed
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#basics" title="Basics" class="md-nav__link">
    Basics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#initialization" title="Initialization" class="md-nav__link">
    Initialization
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tcp-initialization" title="TCP initialization" class="md-nav__link">
    TCP initialization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shared-file-system-initialization" title="Shared file-system initialization" class="md-nav__link">
    Shared file-system initialization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#environment-variable-initialization" title="Environment variable initialization" class="md-nav__link">
    Environment variable initialization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#groups" title="Groups" class="md-nav__link">
    Groups
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#point-to-point-communication" title="Point-to-point communication" class="md-nav__link">
    Point-to-point communication
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#collective-functions" title="Collective functions" class="md-nav__link">
    Collective functions
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../63/" title="Legacy package - torch.legacy" class="md-nav__link">
      Legacy package - torch.legacy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../64/" title="torch.cuda" class="md-nav__link">
      torch.cuda
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../65/" title="torch.utils.ffi" class="md-nav__link">
      torch.utils.ffi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../66/" title="torch.utils.data" class="md-nav__link">
      torch.utils.data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../67/" title="torch.utils.model_zoo" class="md-nav__link">
      torch.utils.model_zoo
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../68/" title="torch.onnx" class="md-nav__link">
      torch.onnx
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../69/" title="torchvision 参考" class="md-nav__link">
      torchvision 参考
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../70/" title="torchvision" class="md-nav__link">
      torchvision
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../71/" title="torchvision.datasets" class="md-nav__link">
      torchvision.datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../72/" title="torchvision.models" class="md-nav__link">
      torchvision.models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../73/" title="torchvision.transforms" class="md-nav__link">
      torchvision.transforms
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../74/" title="torchvision.utils" class="md-nav__link">
      torchvision.utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../75/" title="项目相关" class="md-nav__link">
      项目相关
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../76/" title="项目贡献者" class="md-nav__link">
      项目贡献者
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../77/" title="组织学习交流群" class="md-nav__link">
      组织学习交流群
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#basics" title="Basics" class="md-nav__link">
    Basics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#initialization" title="Initialization" class="md-nav__link">
    Initialization
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tcp-initialization" title="TCP initialization" class="md-nav__link">
    TCP initialization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shared-file-system-initialization" title="Shared file-system initialization" class="md-nav__link">
    Shared file-system initialization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#environment-variable-initialization" title="Environment variable initialization" class="md-nav__link">
    Environment variable initialization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#groups" title="Groups" class="md-nav__link">
    Groups
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#point-to-point-communication" title="Point-to-point communication" class="md-nav__link">
    Point-to-point communication
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#collective-functions" title="Collective functions" class="md-nav__link">
    Collective functions
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/62.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="distributed-communication-package-torchdistributed">Distributed communication package - torch.distributed</h1>
<p>torch.distributed 提供类似 MPI 的前向运算机制, 支持在多台机的网络中交换数据. 支持不同的后段和初始化方法.</p>
<p>目前torch.distributed支持三个后端, 每个都有不同的功能. 下表显示哪些功能可用于 CPU/CUDA 张量. 只有在设备上编译安装PyTorch, 才能在MPI的设备上支持cuda.</p>
<table>
<thead>
<tr>
<th>Backend</th>
<th><code>tcp</code></th>
<th><code>gloo</code></th>
<th><code>mpi</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Device</td>
<td>CPU</td>
<td>GPU</td>
<td>CPU</td>
</tr>
<tr>
<td>---</td>
<td>---</td>
<td>---</td>
<td>---</td>
</tr>
<tr>
<td>send</td>
<td>✓</td>
<td>✘</td>
<td>✘</td>
</tr>
<tr>
<td>recv</td>
<td>✓</td>
<td>✘</td>
<td>✘</td>
</tr>
<tr>
<td>broadcast</td>
<td>✓</td>
<td>✘</td>
<td>✓</td>
</tr>
<tr>
<td>all_reduce</td>
<td>✓</td>
<td>✘</td>
<td>✓</td>
</tr>
<tr>
<td>reduce</td>
<td>✓</td>
<td>✘</td>
<td>✘</td>
</tr>
<tr>
<td>all_gather</td>
<td>✓</td>
<td>✘</td>
<td>✘</td>
</tr>
<tr>
<td>gather</td>
<td>✓</td>
<td>✘</td>
<td>✘</td>
</tr>
<tr>
<td>scatter</td>
<td>✓</td>
<td>✘</td>
<td>✘</td>
</tr>
<tr>
<td>barrier</td>
<td>✓</td>
<td>✘</td>
<td>✓</td>
</tr>
</tbody>
</table>
<h2 id="basics">Basics</h2>
<p>&lt;cite&gt;torch.distributed&lt;/cite&gt; 为在一台或多台机器上运行的多个计算节点提供多进程并行的通信模块和PyTorch的支持. 类 <a href="nn.html#torch.nn.parallel.DistributedDataParallel" title="torch.nn.parallel.DistributedDataParallel"><code>torch.nn.parallel.DistributedDataParallel()</code></a> 建立在这个功能之上, 以提供任何PyTorch模型分布式训练的装饰器. 这个类和 <a href="multiprocessing.html">Multiprocessing package - torch.multiprocessing</a> 和 <a href="nn.html#torch.nn.DataParallel" title="torch.nn.DataParallel"><code>torch.nn.DataParallel()</code></a> 并不相同, PyTorch集群分布式计算支持多台机器, 使用时用户必须在主要训练的脚本中, 明确地将每个进程复制到每台机器中.</p>
<p>在单机多节点计算的情况下, 使用 &lt;cite&gt;torch.distributed&lt;/cite&gt; 和 <a href="nn.html#torch.nn.parallel.DistributedDataParallel" title="torch.nn.parallel.DistributedDataParallel"><code>torch.nn.parallel.DistributedDataParallel()</code></a> 作为 训练的装饰器, 相比于 <a href="nn.html#torch.nn.DataParallel" title="torch.nn.DataParallel"><code>torch.nn.DataParallel()</code></a> 之类的数据并行计算, 任然具有优势:</p>
<ul>
<li>在每次迭代中, 每个进程维护自己的优化器, 执行完整的优化步骤. 虽然这看起来可能是多余的, 但是因为梯度已经被收集在 一起, 并且计算了梯度的平均值, 因此对于每个进程梯度是相同的, 这可以减少在节点之间传递张量, 再计算参数的时间.</li>
<li>每个进程都包含一个独立的Python解释器, 消除了Python解释器的额外开销, 以及由于驱动多线程, 模型副本和GPU造成 “GIL-thrashing” . 对于需要消耗大量Python解释器运行时间 (包括具有循环图层或许多小组件的模型) 的模型来说是非常重要的.</li>
</ul>
<h2 id="initialization">Initialization</h2>
<p>在调用其他模型之前, 这个包需要使用 <a href="#torch.distributed.init_process_group" title="torch.distributed.init_process_group"><code>torch.distributed.init_process_group()</code></a> 函数进行初始化. 在初始化单元中, 所有进程都会参与.</p>
<pre class="codehilite"><code class="language-py">torch.distributed.init_process_group(backend, init_method='env://', **kwargs)</code></pre>


<p>初始化方法.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>backend</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – 使用后端的名字. 输入的有效值包括: <code>tcp</code> , <code>mpi</code> and <code>gloo</code> .</li>
<li><strong>init_method</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>,</em> <em>optional</em>) – 指定如何初始化的URL.</li>
<li><strong>world_size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>,</em> <em>optional</em>) – 参与工作的进程数量.</li>
<li><strong>rank</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>,</em> <em>optional</em>) – 当前进程的排名.</li>
<li><strong>group_name</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>,</em> <em>optional</em>) – 集群的名字. 请参阅init方法的描述.</li>
</ul>
<p>|
| --- | --- |</p>
<p>为了支持 <code>backend == mpi</code> , PyTorch 需要在支持 MPI 的系统上用进行源码编译安装</p>
<pre class="codehilite"><code class="language-py">torch.distributed.get_rank()</code></pre>


<p>返回当前进程的排名.</p>
<p>排名是独一无二的 Rank（排名）是分配给分布式集群中每个进程的唯一标识符. 它们总是连续的整数, 范围从0到 <code>world_size</code> .</p>
<pre class="codehilite"><code class="language-py">torch.distributed.get_world_size()</code></pre>


<p>返回在分布式集群中的进程数目.</p>
<hr />
<p>目前支持三种初始化的方法:</p>
<h3 id="tcp-initialization">TCP initialization</h3>
<p>提供两种TCP的初始化的方法, 两种方法都需要各台机器的网络地址和集群机器数目 <code>world_size</code> . 第一种方法需要指定属于0级进程的地址, 并且初始化时所有进程的等级都由手动指定.</p>
<p>第二种方法是, 地址必须是有效的IP多播地址, 在这种情况下, 可以自动分配等级. 多路通信的初始化也支持 <code>group_name</code> 参数, 它允许你为多个作业使用相同的地址, 只要它们使用不同的小组名即可.</p>
<pre class="codehilite"><code class="language-py">import torch.distributed as dist

# Use address of one of the machines
dist.init_process_group(init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4)

# or a multicast address - rank will be assigned automatically if unspecified
dist.init_process_group(init_method='tcp://[ff15:1e18:5d4c:4cf0:d02d:b659:53ba:b0a7]:23456',
                        world_size=4)</code></pre>


<h3 id="shared-file-system-initialization">Shared file-system initialization</h3>
<p>另一个初始化方法使用一个文件系统, 这个文件系统在一个组中的所有机器上共享和可见, 以及一个所需的 <code>world_size</code> 参数. URL应该以 <code>file://</code> 开头, 并包含一个可以和共享文件系统所有现有目录中的路径相区别的路径, 作为URL. 这个初始化方法也 支持 <code>group_name</code> 参数, 它允许你为多个作业使用相同的共享文件路径, 只要它们使用不同的小组名.</p>
<p>Warning</p>
<p>这种方法假设文件系统支持使用 <code>fcntl</code> 进行锁定 -大多数本地系统和NFS都支持它.</p>
<pre class="codehilite"><code class="language-py">import torch.distributed as dist

# Rank will be assigned automatically if unspecified
dist.init_process_group(init_method='file:///mnt/nfs/sharedfile', world_size=4,
                        group_name=args.group)</code></pre>


<h3 id="environment-variable-initialization">Environment variable initialization</h3>
<p>此方法将从环境变量中读取配置, 从而可以完全自定义如何获取信息. 要设置的变量是:</p>
<ul>
<li><code>MASTER_PORT</code> - 需要; 必须是0级机器上的自由端口</li>
<li><code>MASTER_ADDR</code> - 需要 (除了等级0) ; 等级0节点的地址</li>
<li><code>WORLD_SIZE</code> - 需要; 可以在这里设置, 或者在调用init函数</li>
<li><code>RANK</code> - 需要; 可以在这里设置, 或者在调用init函数</li>
</ul>
<p>等级为0的机器将用于设置所有连接.</p>
<p>这是默认的方法, 这意味着 <code>init_method</code> 不必被特别指定(或者可以是 <code>env://</code> )</p>
<h2 id="groups">Groups</h2>
<p>默认的集群 (collectives) 操作默认的小组 (group), 要求所有的进程进入分布式函数中调用. 一些工作负载可以从可以从更细粒度的通信中受益 这是分布式集群发挥作用的地方. <a href="#torch.distributed.new_group" title="torch.distributed.new_group"><code>new_group()</code></a> 函数可以用来创建新的组, 并且包含所有进程的任意子集. 它返回一个不透明的组句柄, 它可以作为集群的 <code>group</code> 参数 (集群 collectives 是一般的编程模式中的交换信息的分布式函数) .</p>
<pre class="codehilite"><code class="language-py">torch.distributed.new_group(ranks=None)</code></pre>


<p>创建一个新的分布式小组</p>
<p>此函数要求主组中的所有进程（即作为分布式作业一部分的所有进程）都会输入此函数, 即使它们不是该小组的成员. 此外, 应该在所有的进程中以相同的顺序创建新的小组.</p>
<table>
<thead>
<tr>
<th>Parameters:</th>
<th><strong>ranks</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>[</em><a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – 小组内成员的 Rank 的列表.</th>
</tr>
</thead>
<tbody>
<tr>
<td>Returns:</td>
<td>分配组的句柄, 以便在集群中调用.</td>
</tr>
<tr>
<td>---</td>
<td>---</td>
</tr>
</tbody>
</table>
<h2 id="point-to-point-communication">Point-to-point communication</h2>
<pre class="codehilite"><code class="language-py">torch.distributed.send(tensor, dst)</code></pre>


<p>同步发送张量.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 发送的张量.</li>
<li><strong>dst</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – 指定发送的目的地的 Rank.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.recv(tensor, src=None)</code></pre>


<p>同步接收张量.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 用收到的数据填充张量.</li>
<li><strong>src</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>,</em> <em>optional</em>) – 发送端的Rank, 如果没有指定, 将会接收任何发送的数据.</li>
</ul>
<p>|
| --- | --- |
| Returns: | 发送端的Rank. |
| --- | --- |</p>
<p><a href="#torch.distributed.isend" title="torch.distributed.isend"><code>isend()</code></a> 和 <a href="#torch.distributed.irecv" title="torch.distributed.irecv"><code>irecv()</code></a> 使用时返回分布式请求对象. 通常, 这个对象的类型是未指定的, 因为它们不能使用手动创建, 但是它们支持两种方法指定:</p>
<ul>
<li><code>is_completed()</code> - 如果操作完成返回True</li>
<li><code>wait()</code> - 如果操作完成会阻塞所有的进程. <code>is_completed()</code> 如果结果返回, 保证函数返回True.</li>
</ul>
<p>当使用MPI作为后端, <a href="#torch.distributed.isend" title="torch.distributed.isend"><code>isend()</code></a> 和 <a href="#torch.distributed.irecv" title="torch.distributed.irecv"><code>irecv()</code></a> 支持 “不超车” 式的工作方式, 这种方式可以保证消息的顺序. 更多的细节可以看 <a href="http://mpi-forum.org/docs/mpi-2.2/mpi22-report/node54.htm#Node54">http://mpi-forum.org/docs/mpi-2.2/mpi22-report/node54.htm#Node54</a></p>
<pre class="codehilite"><code class="language-py">torch.distributed.isend(tensor, dst)</code></pre>


<p>异步发送张量数据.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 发送的张量的数据.</li>
<li><strong>dst</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – 指定发送到的 Rank.</li>
</ul>
<p>|
| --- | --- |
| Returns: | 分布式请求对象. |
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.irecv(tensor, src)</code></pre>


<p>异步接收张量.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 用收到的数据填充张量.</li>
<li><strong>src</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – 指定发送张量的 Rank.</li>
</ul>
<p>|
| --- | --- |
| Returns: | 一个分布式请求对象. |
| --- | --- |</p>
<h2 id="collective-functions">Collective functions</h2>
<pre class="codehilite"><code class="language-py">torch.distributed.broadcast(tensor, src, group=&lt;object object&gt;)</code></pre>


<p>向某个小组内的张量广播的方法.</p>
<blockquote>
<p><code>tensor</code> 在该小组处理数据的所有过程中元素的数目必须相同.</p>
</blockquote>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 如果发送端 <code>src</code> 是当前进程的 Rank, 则发送数据, 否则使用张量保存接收的数据.</li>
<li><strong>src</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – 发送端的 Rank.</li>
<li><strong>group</strong> (<em>optional</em>) – 集群内的小组的名字.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.all_reduce(tensor, op=&lt;object object&gt;, group=&lt;object object&gt;)</code></pre>


<p>处理所有机器上的处理的张量数据, 计算最终的结果.</p>
<p>在所有进程中调用 <code>tensor</code> 将按位相同.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 集群的输入和输出.</li>
<li><strong>op</strong> (<em>optional</em>) – “torch.distributed.reduce_op” 枚举值之一. 指定用于元素减少的操作.</li>
<li><strong>group</strong> (<em>optional</em>) – 集群的内的小组的名字.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.reduce(tensor, dst, op=&lt;object object&gt;, group=&lt;object object&gt;)</code></pre>


<p>减少所有机器上的张量数据.</p>
<p>只有级别为 <code>dst</code> 的进程才会收到最终结果.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 集群的输入和输出数据. 分别在每台机器上本地处理.</li>
<li><strong>op</strong> (<em>optional</em>) – “torch.distributed.reduce_op” 枚举值之一. 指定用于元素减少的操作.</li>
<li><strong>group</strong> (<em>optional</em>) – 集群的内的小组的名字.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.all_gather(tensor_list, tensor, group=&lt;object object&gt;)</code></pre>


<p>在整个集群中收集list表格中的张量.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor_list</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>[</em><a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – 输出列表. 它应该包含正确大小的张量以用于集体的输出.</li>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 张量从当前进程中进行广播.</li>
<li><strong>group</strong> (<em>optional</em>) – 集群的内的小组的名字.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.gather(tensor, **kwargs)</code></pre>


<p>收集一个张量列表从一个单一进程中.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输入的数据.</li>
<li><strong>dst</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – 目的地的 Rank. 包括除了正在接收数据的进程的所有进程.</li>
<li><strong>gather_list</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>[</em><a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – 用于接收数据的适当大小的张量列表. 只在接收过程中需要.</li>
<li><strong>group</strong> (<em>optional</em>) – 集群的内的小组的名字.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.scatter(tensor, **kwargs)</code></pre>


<p>将张量列表散布到小组中的所有进程.</p>
<p>每个进程只会收到一个张量, 并将其数据存储在 <code>tensor</code> 的参数中.</p>
<p>| Parameters: | </p>
<ul>
<li><strong>tensor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 输出的张量.</li>
<li><strong>src</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – 发送端的 Rank. 包括除了正在接收数据的进程的所有进程.</li>
<li><strong>scatter_list</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a><em>[</em><a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – 张量分散的列表. 仅在发送数据的过程中需要.</li>
<li><strong>group</strong> (<em>optional</em>) – 集群的内的小组的名字.</li>
</ul>
<p>|
| --- | --- |</p>
<pre class="codehilite"><code class="language-py">torch.distributed.barrier(group=&lt;object object&gt;)</code></pre>


<p>同步所有进程.</p>
<p>这个集群阻塞进程, 直到全部的小组的计算结果都输入进这个函数中.</p>
<table>
<thead>
<tr>
<th>Parameters:</th>
<th><strong>group</strong> (<em>optional</em>) – 集群的内的小组的名字.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
                
                  
                
              
              
                


              

              <hr/>
              <div align="center">
                  <p><a href="http://www.apachecn.org/" target="_blank"><font face="KaiTi" size="6" color="red">我们一直在努力</font></a><p>
                  <p><a href="https://github.com/apachecn/pytorch-doc-zh/" target="_blank">apachecn/pytorch-doc-zh</a></p>
                  <p><iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&repo=pytorch-doc-zh&type=watch&count=true&v=2" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
                  <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&repo=pytorch-doc-zh&type=star&count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
                  <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&repo=pytorch-doc-zh&type=fork&count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
                  <a target="_blank" href="//shang.qq.com/wpa/qunwpa?idkey=bcee938030cc9e1552deb3bd9617bbbf62d3ec1647e4b60d9cd6b6e8f78ddc03"><img border="0" src="//pub.idqqimg.com/wpa/images/group.png" alt="ML | ApacheCN" title="ML | ApacheCN"></a></p>
                  <div style="text-align:center;margin:0 0 10.5px;"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
                        <ins class="adsbygoogle"
                             style="display:inline-block;width:728px;height:90px"
                             data-ad-client="ca-pub-3565452474788507"
                             data-ad-slot="2543897000"></ins>
                        <script>
                        (adsbygoogle = window.adsbygoogle || []).push({});
                        </script></div>
              </div>

              <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
              <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
              <div id="gitalk-container" class="container-fluid"></div>
              <script type="text/javascript">
                  var gitalk = new Gitalk({
                  clientID: 'f27b87eb424ba43df978',
                  clientSecret: '9b3482a495c5257a1d269d8108b9bfd71f048c3c',
                  repo: 'pytorch-doc-zh',
                  owner: 'apachecn',
                  admin: ['jiangzhonglian'],
                  id: md5(location.pathname),
                  distractionFreeMode: false
                  })
                  gitalk.render('gitalk-container')
              </script>
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../61/" title="Multiprocessing package - torch.multiprocessing" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                Multiprocessing package - torch.multiprocessing
              </span>
            </div>
          </a>
        
        
          <a href="../63/" title="Legacy package - torch.legacy" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                Legacy package - torch.legacy
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.583bbe55.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>