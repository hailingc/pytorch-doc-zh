



<!DOCTYPE html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="PyTorch 0.3.0 中文文档">
      
      
        <link rel="canonical" href="http://pytorch.apachecn.org/33/">
      
      
        <meta name="author" content="ApacheCN Team">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.0.3">
    
    
      
        <title>用基于注意力机制的seq2seq神经网络进行翻译 - PyTorch 0.3.0 中文文档</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.451f80e5.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#ff7043">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    

    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
        }
    });
    </script>
    
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    
    <!-- google webmaster -->
    <meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo" />
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="deep-orange" data-md-color-accent="deep-orange">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="../#seq2seq" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="http://pytorch.apachecn.org" title="PyTorch 0.3.0 中文文档" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                PyTorch 0.3.0 中文文档
              </span>
              <span class="md-header-nav__topic">
                用基于注意力机制的seq2seq神经网络进行翻译
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/apachecn/pytorch-doc-zh/" title="前往 Github 仓库" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      pytorch-doc-zh
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href=".." title="主页" class="md-tabs__link">
          主页
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../0/" title="中文教程" class="md-tabs__link md-tabs__link--active">
          中文教程
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../45/" title="中文文档" class="md-tabs__link">
          中文文档
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="http://pytorch.apachecn.org" title="PyTorch 0.3.0 中文文档" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    PyTorch 0.3.0 中文文档
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/apachecn/pytorch-doc-zh/" title="前往 Github 仓库" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      pytorch-doc-zh
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      主页
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        主页
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href=".." title="主页" class="md-nav__link">
      主页
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      中文教程
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        中文教程
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../0/" title="初学者教程" class="md-nav__link">
      初学者教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../1/" title="PyTorch 深度学习: 60 分钟极速入门教程" class="md-nav__link">
      PyTorch 深度学习: 60 分钟极速入门教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2/" title="PyTorch 是什么？" class="md-nav__link">
      PyTorch 是什么？
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3/" title="自动求导: 自动微分" class="md-nav__link">
      自动求导: 自动微分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../4/" title="神经网络" class="md-nav__link">
      神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../5/" title="训练一个分类器" class="md-nav__link">
      训练一个分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../6/" title="可选: 数据并行" class="md-nav__link">
      可选: 数据并行
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../7/" title="PyTorch for former Torch users" class="md-nav__link">
      PyTorch for former Torch users
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../8/" title="Tensors" class="md-nav__link">
      Tensors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../9/" title="Autograd (自动求导)" class="md-nav__link">
      Autograd (自动求导)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../10/" title="nn package" class="md-nav__link">
      nn package
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../11/" title="Multi-GPU examples" class="md-nav__link">
      Multi-GPU examples
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../12/" title="跟着例子学习 PyTorch" class="md-nav__link">
      跟着例子学习 PyTorch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../13/" title="Warm-up: numpy" class="md-nav__link">
      Warm-up: numpy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../14/" title="PyTorch: Tensors" class="md-nav__link">
      PyTorch: Tensors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../15/" title="PyTorch: 变量和autograd" class="md-nav__link">
      PyTorch: 变量和autograd
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../16/" title="PyTorch: 定义新的autograd函数" class="md-nav__link">
      PyTorch: 定义新的autograd函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../17/" title="TensorFlow: 静态图" class="md-nav__link">
      TensorFlow: 静态图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../18/" title="PyTorch: nn包" class="md-nav__link">
      PyTorch: nn包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../19/" title="PyTorch: optim包" class="md-nav__link">
      PyTorch: optim包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../20/" title="PyTorch: 定制化nn模块" class="md-nav__link">
      PyTorch: 定制化nn模块
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../21/" title="PyTorch: 动态控制流程 + 权重共享" class="md-nav__link">
      PyTorch: 动态控制流程 + 权重共享
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../22/" title="迁移学习教程" class="md-nav__link">
      迁移学习教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../23/" title="数据加载和处理教程" class="md-nav__link">
      数据加载和处理教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../24/" title="针对NLP的Pytorch深度学习" class="md-nav__link">
      针对NLP的Pytorch深度学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../25/" title="PyTorch介绍" class="md-nav__link">
      PyTorch介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../26/" title="PyTorch深度学习" class="md-nav__link">
      PyTorch深度学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../27/" title="词汇嵌入:编码词汇语义" class="md-nav__link">
      词汇嵌入:编码词汇语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../28/" title="序列模型和 LSTM 网络（长短记忆网络）" class="md-nav__link">
      序列模型和 LSTM 网络（长短记忆网络）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../29/" title="高级教程: 作出动态决策和 Bi-LSTM CRF" class="md-nav__link">
      高级教程: 作出动态决策和 Bi-LSTM CRF
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../30/" title="中级教程" class="md-nav__link">
      中级教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../31/" title="用字符级RNN分类名称" class="md-nav__link">
      用字符级RNN分类名称
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../32/" title="基与字符级RNN（Char-RNN）的人名生成" class="md-nav__link">
      基与字符级RNN（Char-RNN）的人名生成
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        用基于注意力机制的seq2seq神经网络进行翻译
      </label>
    
    <a href="./" title="用基于注意力机制的seq2seq神经网络进行翻译" class="md-nav__link md-nav__link--active">
      用基于注意力机制的seq2seq神经网络进行翻译
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="加载数据文件" class="md-nav__link">
    加载数据文件
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seq_1" title="Seq2Seq模型" class="md-nav__link">
    Seq2Seq模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="编码器" class="md-nav__link">
    编码器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="解码器" class="md-nav__link">
    解码器
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" title="简单的解码器" class="md-nav__link">
    简单的解码器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="注意力解码器" class="md-nav__link">
    注意力解码器
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" title="训练模型" class="md-nav__link">
    训练模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" title="绘制结果" class="md-nav__link">
    绘制结果
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" title="评估" class="md-nav__link">
    评估
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" title="训练和评估" class="md-nav__link">
    训练和评估
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_10" title="可视化注意力" class="md-nav__link">
    可视化注意力
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" title="练习" class="md-nav__link">
    练习
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../34/" title="强化学习（DQN）教程" class="md-nav__link">
      强化学习（DQN）教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../35/" title="Writing Distributed Applications with PyTorch" class="md-nav__link">
      Writing Distributed Applications with PyTorch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../36/" title="空间转换网络 (Spatial Transformer Networks) 教程" class="md-nav__link">
      空间转换网络 (Spatial Transformer Networks) 教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../37/" title="高级教程" class="md-nav__link">
      高级教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../38/" title="用 PyTorch 做 神经转换 (Neural Transfer)" class="md-nav__link">
      用 PyTorch 做 神经转换 (Neural Transfer)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../39/" title="使用 numpy 和 scipy 创建扩展" class="md-nav__link">
      使用 numpy 和 scipy 创建扩展
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../40/" title="使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile" class="md-nav__link">
      使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../41/" title="为 pytorch 自定义 C 扩展" class="md-nav__link">
      为 pytorch 自定义 C 扩展
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../42/" title="项目相关" class="md-nav__link">
      项目相关
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../43/" title="项目贡献者" class="md-nav__link">
      项目贡献者
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../44/" title="组织学习交流群" class="md-nav__link">
      组织学习交流群
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      中文文档
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        中文文档
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../45/" title="介绍" class="md-nav__link">
      介绍
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../46/" title="自动求导机制" class="md-nav__link">
      自动求导机制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../47/" title="广播语义" class="md-nav__link">
      广播语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../48/" title="CUDA 语义" class="md-nav__link">
      CUDA 语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../49/" title="扩展 PyTorch" class="md-nav__link">
      扩展 PyTorch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../50/" title="多进程的最佳实践" class="md-nav__link">
      多进程的最佳实践
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../51/" title="序列化语义" class="md-nav__link">
      序列化语义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../52/" title="Package 参考" class="md-nav__link">
      Package 参考
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../53/" title="torch" class="md-nav__link">
      torch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../54/" title="torch.Tensor" class="md-nav__link">
      torch.Tensor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../55/" title="torch.sparse" class="md-nav__link">
      torch.sparse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../56/" title="torch.Storage" class="md-nav__link">
      torch.Storage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../57/" title="torch.nn" class="md-nav__link">
      torch.nn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../58/" title="torch.optim" class="md-nav__link">
      torch.optim
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../59/" title="Automatic differentiation package - torch.autograd" class="md-nav__link">
      Automatic differentiation package - torch.autograd
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../60/" title="Probability distributions - torch.distributions" class="md-nav__link">
      Probability distributions - torch.distributions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../61/" title="Multiprocessing package - torch.multiprocessing" class="md-nav__link">
      Multiprocessing package - torch.multiprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../62/" title="Distributed communication package - torch.distributed" class="md-nav__link">
      Distributed communication package - torch.distributed
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../63/" title="Legacy package - torch.legacy" class="md-nav__link">
      Legacy package - torch.legacy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../64/" title="torch.cuda" class="md-nav__link">
      torch.cuda
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../65/" title="torch.utils.ffi" class="md-nav__link">
      torch.utils.ffi
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../66/" title="torch.utils.data" class="md-nav__link">
      torch.utils.data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../67/" title="torch.utils.model_zoo" class="md-nav__link">
      torch.utils.model_zoo
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../68/" title="torch.onnx" class="md-nav__link">
      torch.onnx
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../69/" title="torchvision 参考" class="md-nav__link">
      torchvision 参考
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../70/" title="torchvision" class="md-nav__link">
      torchvision
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../71/" title="torchvision.datasets" class="md-nav__link">
      torchvision.datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../72/" title="torchvision.models" class="md-nav__link">
      torchvision.models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../73/" title="torchvision.transforms" class="md-nav__link">
      torchvision.transforms
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../74/" title="torchvision.utils" class="md-nav__link">
      torchvision.utils
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../75/" title="项目相关" class="md-nav__link">
      项目相关
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../76/" title="项目贡献者" class="md-nav__link">
      项目贡献者
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../77/" title="组织学习交流群" class="md-nav__link">
      组织学习交流群
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="加载数据文件" class="md-nav__link">
    加载数据文件
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seq_1" title="Seq2Seq模型" class="md-nav__link">
    Seq2Seq模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" title="编码器" class="md-nav__link">
    编码器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="解码器" class="md-nav__link">
    解码器
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" title="简单的解码器" class="md-nav__link">
    简单的解码器
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="注意力解码器" class="md-nav__link">
    注意力解码器
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" title="训练模型" class="md-nav__link">
    训练模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" title="绘制结果" class="md-nav__link">
    绘制结果
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" title="评估" class="md-nav__link">
    评估
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" title="训练和评估" class="md-nav__link">
    训练和评估
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_10" title="可视化注意力" class="md-nav__link">
    可视化注意力
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" title="练习" class="md-nav__link">
    练习
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/33.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="seq2seq">用基于注意力机制的seq2seq神经网络进行翻译</h1>
<p><strong>作者</strong>: <a href="https://github.com/spro/practical-pytorch">Sean Robertson</a></p>
<p>这个教程主要讲解用一个神经网络将法语翻译成英语.</p>
<pre class="codehilite"><code class="language-py">[KEY: &gt; input, = target, &lt; output]

&gt; il est en train de peindre un tableau .
= he is painting a picture .
&lt; he is painting a picture .

&gt; pourquoi ne pas essayer ce vin delicieux ?
= why not try that delicious wine ?
&lt; why not try that delicious wine ?

&gt; elle n est pas poete mais romanciere .
= she is not a poet but a novelist .
&lt; she not not a poet but a novelist .

&gt; vous etes trop maigre .
= you re too skinny .
&lt; you re all alone .</code></pre>


<p>… 取得不同阶段的成功.</p>
<p>这是通过<code>seq2seq网络 &amp;lt;[http://arxiv.org/abs/1409.3215](http://arxiv.org/abs/1409.3215)&amp;gt;</code>__实现的简单却强大的想法, 通过两个递归神经网络一起工作实现将一个序列转换为另一个.一个编码器网络将输入序列压 缩成向量,解码器网络将该矢量展开为新的序列.</p>
<p><img alt="" src="../img/33f7cf98243cd260e31082eb21f24f50.jpg" /></p>
<p>为了改进这个模型,我们将使用一种<code>注意力机制&amp;lt;[https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473)&amp;gt;</code>__, 它可以让解码器学习将注意力集中在输入序列的特定范围上.</p>
<p><strong>推荐阅读:</strong></p>
<p>我们假设你至少已经安装了PyTorch,了解Python,并且了解张量:</p>
<ul>
<li><a href="http://pytorch.org/">http://pytorch.org/</a> PyTorch安装说明</li>
<li><a href="../beginner/deep_learning_60min_blitz.html">PyTorch 深度学习: 60 分钟极速入门教程</a> 开始使用PyTorch</li>
<li><a href="../beginner/pytorch_with_examples.html">跟着例子学习 PyTorch</a> 进行广泛而深入的了解</li>
<li><a href="../beginner/former_torchies_tutorial.html">PyTorch for former Torch users</a> 如果你是前Lua Torch用户</li>
</ul>
<p>这些内容也有利于了解seq2seq网络和其工作机制:</p>
<ul>
<li><a href="http://arxiv.org/abs/1406.1078">用RNN编码器 - 解码器来学习用于统计机器翻译的短语表示</a></li>
<li><a href="http://arxiv.org/abs/1409.3215">用神经网络进行seq2seq学习</a></li>
<li><a href="https://arxiv.org/abs/1409.0473">神经网络机器翻译联合学习对齐和翻译</a></li>
<li><a href="http://arxiv.org/abs/1506.05869">神经会话模型</a></li>
</ul>
<p>你还可以找到以前的教程关于Character-Level RNN名称分类 <a href="char_rnn_classification_tutorial.html">用字符级RNN分类名称</a> 和生成名称 <a href="char_rnn_generation_tutorial.html">基与字符级RNN（Char-RNN）的人名生成</a> 这些概念与编码器和解码器模型非常相似.</p>
<p>更多内容请阅读介绍这些主题的论文:</p>
<ul>
<li><a href="http://arxiv.org/abs/1406.1078">用RNN编码器 - 解码器来学习用于统计机器翻译的短语表示</a></li>
<li><a href="http://arxiv.org/abs/1409.3215">用神经网络进行seq2seq学习</a></li>
<li><a href="https://arxiv.org/abs/1409.0473">神经网络机器翻译联合学习对齐和翻译</a></li>
<li><a href="http://arxiv.org/abs/1506.05869">神经会话模型</a></li>
</ul>
<p><strong>要求</strong></p>
<pre class="codehilite"><code class="language-py">from __future__ import unicode_literals, print_function, division
from io import open
import unicodedata
import string
import re
import random

import torch
import torch.nn as nn
from torch.autograd import Variable
from torch import optim
import torch.nn.functional as F

use_cuda = torch.cuda.is_available()</code></pre>


<h2 id="_1">加载数据文件</h2>
<p>这个项目的数据是一组数以千计的英语到法语的翻译对.</p>
<p>[<code>](#id2)这个问题在 Open Data Stack Exchange上 &lt;[http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages](http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages)&gt;</code>__</p>
<p>指导我们使用开放的翻译网站 <a href="http://tatoeba.org/">http://tatoeba.org/</a> 可下载地址为 <a href="http://tatoeba.org/eng/downloads">http://tatoeba.org/eng/downloads</a> - 更好的是, 有人做了额外的工作,切分语言对到单个文本文件中: <a href="http://www.manythings.org/anki/">http://www.manythings.org/anki/</a></p>
<p>英文到法文对太大而不能包含在repo中,因此开始前请下载 <code>data/eng-fra.txt</code>. 该文件是一个制表符分隔的翻译对列表: :</p>
<pre class="codehilite"><code class="language-py">I am cold.    Je suis froid.</code></pre>


<p>Note</p>
<p>下载数据文件在 <a href="https://download.pytorch.org/tutorial/data.zip">这里</a> 并解压到正确的路径.</p>
<p>与character-level RNN教程中使用的字符编码类似,我们将用语言中的每个单词 作为独热向量,或者除了单个单词之外(在单词的索引处)的大的零向量. 相较于可能 存在于一种语言中仅有十个字符相比,多数都是有大量的字,因此编码向量很大. 然而,我们会欺骗性的做一些数据修剪,保证每种语言只使用几千字.</p>
<p><img alt="" src="../img/9a041cf9cdd24929e1e720fe7397ce9e.jpg" />我们需要每个单词对应唯一的索引作为稍后的网络输入和目标.为了追踪这些索引我们使用一个帮助类 <code>Lang</code> 类中有 词 → 索引 (<code>word2index</code>) 和 索引 → 词</p>
<p>(<code>index2word</code>) 的字典, 以及每个词<code>word2count</code> 用来替换稀疏词汇.</p>
<pre class="codehilite"><code class="language-py">SOS_token = 0
EOS_token = 1

class Lang:
    def __init__(self, name):
        self.name = name
        self.word2index = {}
        self.word2count = {}
        self.index2word = {0: &quot;SOS&quot;, 1: &quot;EOS&quot;}
        self.n_words = 2  # Count SOS and EOS

    def addSentence(self, sentence):
        for word in sentence.split(' '):
            self.addWord(word)

    def addWord(self, word):
        if word not in self.word2index:
            self.word2index[word] = self.n_words
            self.word2count[word] = 1
            self.index2word[self.n_words] = word
            self.n_words += 1
        else:
            self.word2count[word] += 1</code></pre>


<p>这些文件全部采用Unicode编码,为了简化我们将Unicode字符转换为ASCII, 使所有内容小写,并修剪大部分标点符号.</p>
<pre class="codehilite"><code class="language-py"># 感谢您将Unicode字符串转换为纯ASCII
# http://stackoverflow.com/a/518232/2809427
def unicodeToAscii(s):
    return ''.join(
        c for c in unicodedata.normalize('NFD', s)
        if unicodedata.category(c) != 'Mn'
    )

# 小写,修剪和删除非字母字符

def normalizeString(s):
    s = unicodeToAscii(s.lower().strip())
    s = re.sub(r&quot;([.!?])&quot;, r&quot; \1&quot;, s)
    s = re.sub(r&quot;[^a-zA-Z.!?]+&quot;, r&quot; &quot;, s)
    return s</code></pre>


<p>要读取数据文件,我们将把文件分成行,然后将行成对分开. 这些文件都是英文→其他语言,所以如果我们想从其他语言翻译→英文,我们添加了 翻转标志 [<code>](#id5)reverse</code>来翻转词语对.</p>
<pre class="codehilite"><code class="language-py">def readLangs(lang1, lang2, reverse=False):
    print(&quot;Reading lines...&quot;)

    # 读取文件并按行分开
    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\
        read().strip().split('\n')

    # 将每一行分成两列并进行标准化
    pairs = [[normalizeString(s) for s in l.split('\t')] for l in lines]

    # 翻转对,Lang实例化
    if reverse:
        pairs = [list(reversed(p)) for p in pairs]
        input_lang = Lang(lang2)
        output_lang = Lang(lang1)
    else:
        input_lang = Lang(lang1)
        output_lang = Lang(lang2)

    return input_lang, output_lang, pairs</code></pre>


<p>由于有很多例句,我们希望快速训练,我们会将数据集裁剪为相对简短的句子. 这里的单词的最大长度是10词(包括结束标点符号),我们正在过滤到翻译 成”I am”或”He is”等形式的句子.(考虑到先前替换了撇号).</p>
<pre class="codehilite"><code class="language-py">MAX_LENGTH = 10

eng_prefixes = (
    &quot;i am &quot;, &quot;i m &quot;,
    &quot;he is&quot;, &quot;he s &quot;,
    &quot;she is&quot;, &quot;she s&quot;,
    &quot;you are&quot;, &quot;you re &quot;,
    &quot;we are&quot;, &quot;we re &quot;,
    &quot;they are&quot;, &quot;they re &quot;
)

def filterPair(p):
    return len(p[0].split(' ')) &lt; MAX_LENGTH and \
        len(p[1].split(' ')) &lt; MAX_LENGTH and \
        p[1].startswith(eng_prefixes)

def filterPairs(pairs):
    return [pair for pair in pairs if filterPair(pair)]</code></pre>


<p>完整的准备数据的过程:</p>
<ul>
<li>加载文本文件切分成行,并切分成单词对:</li>
<li>文本归一化, 按照长度和内容过滤</li>
<li>从成对的句子中制作单词列表</li>
</ul>
<pre class="codehilite"><code class="language-py">def prepareData(lang1, lang2, reverse=False):
    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)
    print(&quot;Read %s sentence pairs&quot; % len(pairs))
    pairs = filterPairs(pairs)
    print(&quot;Trimmed to %s sentence pairs&quot; % len(pairs))
    print(&quot;Counting words...&quot;)
    for pair in pairs:
        input_lang.addSentence(pair[0])
        output_lang.addSentence(pair[1])
    print(&quot;Counted words:&quot;)
    print(input_lang.name, input_lang.n_words)
    print(output_lang.name, output_lang.n_words)
    return input_lang, output_lang, pairs

input_lang, output_lang, pairs = prepareData('eng', 'fra', True)
print(random.choice(pairs))</code></pre>


<h2 id="seq2seq_1">Seq2Seq模型</h2>
<p>递归神经网络(RNN),是一个按照一个序列进行操作的网路,并 将其自己的输出用作后续步骤的输入.</p>
<p>一个 <a href="http://arxiv.org/abs/1409.3215">序列到序列网络</a>, 或 seq2seq 网络, 或 <a href="https://arxiv.org/pdf/1406.1078v3.pdf">编码解码器网络</a>, 是由两个称为编码器和解码器的RNN组成的模型. 编码器读取输入序列并输出单个向量, 解码器读取该向量以产生输出序列.</p>
<p><img alt="" src="../img/33f7cf98243cd260e31082eb21f24f50.jpg" /></p>
<p>与单个RNN的序列预测不同,每个输入对应一个输出, seq2seq模型将我们从序列长度和顺序中解放出来, 这使得它成为两种语言之间翻译的理想选择.</p>
<p>考虑这句话 “Je ne suis pas le chat noir” → “I am not the black cat”. 输入句子中的大部分单词在输出句子中有直接翻译, 但顺序略有不同,例如: “chat noir” 和 “black cat”. 由于 “ne/pas”结构, 其中另一个单词在输入的句子中. 直接从输入词的序列中直接生成正确的翻译是很困难的.</p>
<p>使用seq2seq模型,编码器会创建一个单独的向量, 在理想情况下,它将输入序列的”含义”编码为单个向量 - 句子的N维空间中的一个点.</p>
<h3 id="_2">编码器</h3>
<p>seq2seq网络的编码器是一个RNN,它为输入句子中的每个单词输出一些值. 对于每个输入字,编码器输出一个向量和一个隐藏状态,并将隐藏状态用于下一个输入字.</p>
<p><img alt="" src="../img/92f408ddeff0a10ad4d3f1961e027b60.jpg" /></p>
<pre class="codehilite"><code class="language-py">class EncoderRNN(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(EncoderRNN, self).__init__()
        self.hidden_size = hidden_size

        self.embedding = nn.Embedding(input_size, hidden_size)
        self.gru = nn.GRU(hidden_size, hidden_size)

    def forward(self, input, hidden):
        embedded = self.embedding(input).view(1, 1, -1)
        output = embedded
        output, hidden = self.gru(output, hidden)
        return output, hidden

    def initHidden(self):
        result = Variable(torch.zeros(1, 1, self.hidden_size))
        if use_cuda:
            return result.cuda()
        else:
            return result</code></pre>


<h3 id="_3">解码器</h3>
<p>解码器是另一个RNN,它接收编码器输出向量并输出一个单词序列来创建翻译.</p>
<h4 id="_4">简单的解码器</h4>
<p>在最简单的seq2seq解码器中,我们只使用编码器的最后一个输出. 这个最后的输出有时称为上下文向量,因为它从整个序列编码上下文. 该上下文向量被用作解码器的初始隐藏状态.</p>
<p>在解码的每一步,解码器都被赋予一个输入指令和隐藏状态. 初始输入指令字符串开始的<code>&amp;lt;SOS&amp;gt;</code>指令,第一个隐藏状态是上下文向量(编码器的最后隐藏状态).</p>
<p><img alt="" src="../img/fe8c319379c378a0465b297c6626fb63.jpg" /></p>
<pre class="codehilite"><code class="language-py">class DecoderRNN(nn.Module):
    def __init__(self, hidden_size, output_size):
        super(DecoderRNN, self).__init__()
        self.hidden_size = hidden_size

        self.embedding = nn.Embedding(output_size, hidden_size)
        self.gru = nn.GRU(hidden_size, hidden_size)
        self.out = nn.Linear(hidden_size, output_size)
        self.softmax = nn.LogSoftmax(dim=1)

    def forward(self, input, hidden):
        output = self.embedding(input).view(1, 1, -1)
        output = F.relu(output)
        output, hidden = self.gru(output, hidden)
        output = self.softmax(self.out(output[0]))
        return output, hidden

    def initHidden(self):
        result = Variable(torch.zeros(1, 1, self.hidden_size))
        if use_cuda:
            return result.cuda()
        else:
            return result</code></pre>


<p>我们鼓励你训练和观察这个模型的结果,但为了节省空间,我们将直接进正题引入注意力机制.</p>
<h4 id="_5">注意力解码器</h4>
<p>如果仅在编码器和解码器之间传递上下文向量,则该单个向量承担编码整个句子的负担.</p>
<p>注意力允许解码器网络针对解码器自身输出的每一步”聚焦”编码器输出的不同部分. 首先我们计算一组注意力权重. 这些将被乘以编码器输出矢量获得加权的组合. 结果(在代码中为<code>attn_applied</code>) 应该包含关于输入序列的特定部分的信息, 从而帮助解码器选择正确的输出单词.</p>
<p><img alt="" src="../img/3313f4800c7d01049e2a2ef2079e5905.jpg" /></p>
<p>使用解码器的输入和隐藏状态作为输入,利用另一个前馈层 [<code>](#id12)attn</code>计算注意力权重, 由于训练数据中有各种大小的句子,为了实际创建和训练此层, 我们必须选择最大长度的句子(输入长度,用于编码器输出),以适用于此层. 最大长度的句子将使用所有注意力权重,而较短的句子只使用前几个.</p>
<p><img alt="" src="../img/dd6f408715e145310fe25f9e6e2bbc79.jpg" /></p>
<pre class="codehilite"><code class="language-py">class AttnDecoderRNN(nn.Module):
    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):
        super(AttnDecoderRNN, self).__init__()
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.dropout_p = dropout_p
        self.max_length = max_length

        self.embedding = nn.Embedding(self.output_size, self.hidden_size)
        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)
        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)
        self.dropout = nn.Dropout(self.dropout_p)
        self.gru = nn.GRU(self.hidden_size, self.hidden_size)
        self.out = nn.Linear(self.hidden_size, self.output_size)

    def forward(self, input, hidden, encoder_outputs):
        embedded = self.embedding(input).view(1, 1, -1)
        embedded = self.dropout(embedded)

        attn_weights = F.softmax(
            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)
        attn_applied = torch.bmm(attn_weights.unsqueeze(0),
                                 encoder_outputs.unsqueeze(0))

        output = torch.cat((embedded[0], attn_applied[0]), 1)
        output = self.attn_combine(output).unsqueeze(0)

        output = F.relu(output)
        output, hidden = self.gru(output, hidden)

        output = F.log_softmax(self.out(output[0]), dim=1)
        return output, hidden, attn_weights

    def initHidden(self):
        result = Variable(torch.zeros(1, 1, self.hidden_size))
        if use_cuda:
            return result.cuda()
        else:
            return result</code></pre>


<p>Note</p>
<p>还有其他形式的注意力通过使用相对位置方法来解决长度限制. 阅读关于 “local attention” 在 <a href="https://arxiv.org/abs/1508.04025">基于注意力的神经机器翻译的有效途径</a>.为了训练,对于每一对我们将需要输入的张量(输入句子中的词的索引)和 目标张量(目标语句中的词的索引). 在创建这些向量时,我们会将EOS标记添加到两个序列中.</p>
<pre class="codehilite"><code class="language-py">def indexesFromSentence(lang, sentence):
    return [lang.word2index[word] for word in sentence.split(' ')]

def variableFromSentence(lang, sentence):
    indexes = indexesFromSentence(lang, sentence)
    indexes.append(EOS_token)
    result = Variable(torch.LongTensor(indexes).view(-1, 1))
    if use_cuda:
        return result.cuda()
    else:
        return result

def variablesFromPair(pair):
    input_variable = variableFromSentence(input_lang, pair[0])
    target_variable = variableFromSentence(output_lang, pair[1])
    return (input_variable, target_variable)</code></pre>


<h3 id="_6">训练模型</h3>
<p>为了训练我们通过编码器运行输入句子,并跟踪每个输出和最新的隐藏状态. 然后解码器被赋予<code>&amp;lt;SOS&amp;gt;</code> 指令作为其第一个输入, 并将编码器的最后一个隐藏状态作为其第一个隐藏状态.</p>
<p>“Teacher forcing” 是将实际目标输出用作每个下一个输入的概念,而不是将解码器的 猜测用作下一个输入.使用教师强迫会使其更快地收敛,但是 <a href="http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf">当训练好的网络被利用时,它可能表现出不稳定性.</a>.</p>
<p>你可以观察教师强迫网络的输出,这些网络是用连贯的语法阅读的,但却远离了正确的翻译 - 直观地来看它已经学会了代表输出语法,并且一旦老师告诉它前几个单词,就可以”拾取”它的意思,</p>
<blockquote>
<p>但它没有适当地学会如何从翻译中创建句子.</p>
</blockquote>
<p>由于PyTorch的autograd给我们的自由,我们可以随意选择使用老师强制或不使用简单的if语句. 打开<code>teacher_forcing_ratio</code>更多的使用它.</p>
<pre class="codehilite"><code class="language-py">teacher_forcing_ratio = 0.5

def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):
    encoder_hidden = encoder.initHidden()

    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    input_length = input_variable.size()[0]
    target_length = target_variable.size()[0]

    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))
    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs

    loss = 0

    for ei in range(input_length):
        encoder_output, encoder_hidden = encoder(
            input_variable[ei], encoder_hidden)
        encoder_outputs[ei] = encoder_output[0][0]

    decoder_input = Variable(torch.LongTensor([[SOS_token]]))
    decoder_input = decoder_input.cuda() if use_cuda else decoder_input

    decoder_hidden = encoder_hidden

    use_teacher_forcing = True if random.random() &lt; teacher_forcing_ratio else False

    if use_teacher_forcing:
        # 教师强制: 将目标作为下一个输入
        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_attention = decoder(
                decoder_input, decoder_hidden, encoder_outputs)
            loss += criterion(decoder_output, target_variable[di])
            decoder_input = target_variable[di]  # Teacher forcing

    else:
        # 没有教师强迫: 使用自己的预测作为下一个输入
        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_attention = decoder(
                decoder_input, decoder_hidden, encoder_outputs)
            topv, topi = decoder_output.data.topk(1)
            ni = topi[0][0]

            decoder_input = Variable(torch.LongTensor([[ni]]))
            decoder_input = decoder_input.cuda() if use_cuda else decoder_input

            loss += criterion(decoder_output, target_variable[di])
            if ni == EOS_token:
                break

    loss.backward()

    encoder_optimizer.step()
    decoder_optimizer.step()

    return loss.data[0] / target_length</code></pre>


<p>根据当前时间和进度百分比,这是一个帮助功能,用于打印经过的时间和估计的剩余时间.</p>
<pre class="codehilite"><code class="language-py">import time
import math

def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)

def timeSince(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))</code></pre>


<p>整个训练过程如下所示:</p>
<ul>
<li>启动一个计时器</li>
<li>初始化优化器和标准</li>
<li>创建一组训练对</li>
<li>为绘图建空损失数组</li>
</ul>
<p>然后我们多次调用<code>train</code>,偶尔打印进度(样本的百分比,到目前为止的时间,估计的时间)和平均损失.</p>
<pre class="codehilite"><code class="language-py">def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):
    start = time.time()
    plot_losses = []
    print_loss_total = 0  # Reset every print_every
    plot_loss_total = 0  # Reset every plot_every

    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)
    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)
    training_pairs = [variablesFromPair(random.choice(pairs))
                      for i in range(n_iters)]
    criterion = nn.NLLLoss()

    for iter in range(1, n_iters + 1):
        training_pair = training_pairs[iter - 1]
        input_variable = training_pair[0]
        target_variable = training_pair[1]

        loss = train(input_variable, target_variable, encoder,
                     decoder, encoder_optimizer, decoder_optimizer, criterion)
        print_loss_total += loss
        plot_loss_total += loss

        if iter % print_every == 0:
            print_loss_avg = print_loss_total / print_every
            print_loss_total = 0
            print('%s (%d  %d%%) %.4f' % (timeSince(start, iter / n_iters),
                                         iter, iter / n_iters * 100, print_loss_avg))

        if iter % plot_every == 0:
            plot_loss_avg = plot_loss_total / plot_every
            plot_losses.append(plot_loss_avg)
            plot_loss_total = 0

    showPlot(plot_losses)</code></pre>


<h3 id="_7">绘制结果</h3>
<p>使用matplotlib完成绘图, 使用训练时保存的损失值<code>plot_losses</code>数组.</p>
<pre class="codehilite"><code class="language-py">import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np

def showPlot(points):
    plt.figure()
    fig, ax = plt.subplots()
    # 这个定位器会定期发出提示信息
    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.plot(points)</code></pre>


<h2 id="_8">评估</h2>
<p>评估与训练大部分相同,但没有目标,因此我们只是将解码器的每一步预测反馈给它自身. 每当它预测到一个单词时,我们就会将它添加到输出字符串中,并且如果它预测到我们在那里停止的EOS指令. 我们还存储解码器的注意力输出以供稍后显示.</p>
<pre class="codehilite"><code class="language-py">def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):
    input_variable = variableFromSentence(input_lang, sentence)
    input_length = input_variable.size()[0]
    encoder_hidden = encoder.initHidden()

    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))
    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs

    for ei in range(input_length):
        encoder_output, encoder_hidden = encoder(input_variable[ei],
                                                 encoder_hidden)
        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]

    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS
    decoder_input = decoder_input.cuda() if use_cuda else decoder_input

    decoder_hidden = encoder_hidden

    decoded_words = []
    decoder_attentions = torch.zeros(max_length, max_length)

    for di in range(max_length):
        decoder_output, decoder_hidden, decoder_attention = decoder(
            decoder_input, decoder_hidden, encoder_outputs)
        decoder_attentions[di] = decoder_attention.data
        topv, topi = decoder_output.data.topk(1)
        ni = topi[0][0]
        if ni == EOS_token:
            decoded_words.append('&lt;EOS&gt;')
            break
        else:
            decoded_words.append(output_lang.index2word[ni])

        decoder_input = Variable(torch.LongTensor([[ni]]))
        decoder_input = decoder_input.cuda() if use_cuda else decoder_input

    return decoded_words, decoder_attentions[:di + 1]</code></pre>


<p>我们可以从训练集中评估随机的句子并打印出输入,目标和输出以作出一些主观质量判断:</p>
<pre class="codehilite"><code class="language-py">def evaluateRandomly(encoder, decoder, n=10):
    for i in range(n):
        pair = random.choice(pairs)
        print('&gt;', pair[0])
        print('=', pair[1])
        output_words, attentions = evaluate(encoder, decoder, pair[0])
        output_sentence = ' '.join(output_words)
        print('&lt;', output_sentence)
        print('')</code></pre>


<h2 id="_9">训练和评估</h2>
<p>有了所有这些辅助功能(它看起来像是额外的工作,但它使运行多个实验更容易), 我们就立马可以初始化网络并开始培训.</p>
<p>请记住输入句子被严重过滤, 对于这个小数据集,我们可以使用包含256个隐藏节点 和单个GRU层的相对较小的网络.在MacBook CPU上约40分钟后,我们会得到一些合理的结果.</p>
<p>Note</p>
<p>如果你运行这个notebook,你可以训练,打断内核,评估并在以后继续训练. 注释编码器和解码器初始化的行并再次运行 <code>trainIters</code> .</p>
<pre class="codehilite"><code class="language-py">hidden_size = 256
encoder1 = EncoderRNN(input_lang.n_words, hidden_size)
attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)

if use_cuda:
    encoder1 = encoder1.cuda()
    attn_decoder1 = attn_decoder1.cuda()

trainIters(encoder1, attn_decoder1, 75000, print_every=5000)</code></pre>


<pre class="codehilite"><code class="language-py">evaluateRandomly(encoder1, attn_decoder1)</code></pre>


<h3 id="_10">可视化注意力</h3>
<p>注意力机制的一个有用特性是其高度可解释的输出. 由于它用于对输入序列的特定编码器输出进行加权,因此我们可以想象在每个时间步骤中查看网络最关注的位置.</p>
<p>您可以简单地运行 <code>plt.matshow(attentions)</code>,将注意力输出显示为矩阵, 其中列是输入步骤,行是输出步骤.</p>
<pre class="codehilite"><code class="language-py">output_words, attentions = evaluate(
    encoder1, attn_decoder1, &quot;je suis trop froid .&quot;)
plt.matshow(attentions.numpy())</code></pre>


<p>为了获得更好的观看体验,我们将额外添加轴和标签:</p>
<pre class="codehilite"><code class="language-py">def showAttention(input_sentence, output_words, attentions):
    # 用颜色条设置图形
    fig = plt.figure()
    ax = fig.add_subplot(111)
    cax = ax.matshow(attentions.numpy(), cmap='bone')
    fig.colorbar(cax)

    # 设置轴
    ax.set_xticklabels([''] + input_sentence.split(' ') +
                       ['&lt;EOS&gt;'], rotation=90)
    ax.set_yticklabels([''] + output_words)

    # 在每个打勾处显示标签
    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))
    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))

    plt.show()

def evaluateAndShowAttention(input_sentence):
    output_words, attentions = evaluate(
        encoder1, attn_decoder1, input_sentence)
    print('input =', input_sentence)
    print('output =', ' '.join(output_words))
    showAttention(input_sentence, output_words, attentions)

evaluateAndShowAttention(&quot;elle a cinq ans de moins que moi .&quot;)

evaluateAndShowAttention(&quot;elle est trop petit .&quot;)

evaluateAndShowAttention(&quot;je ne crains pas de mourir .&quot;)

evaluateAndShowAttention(&quot;c est un jeune directeur plein de talent .&quot;)</code></pre>


<h2 id="_11">练习</h2>
<ul>
<li>尝试使用不同的数据集<ul>
<li>另一种语言对</li>
<li>人 → 机器 (例如. IOT 命令)</li>
<li>聊天 → 响应</li>
<li>问题 → 回答</li>
</ul>
</li>
<li>用预先训练的词嵌入替换嵌入,例如word2vec或GloVe</li>
<li>尝试更多图层,更多隐藏单位和更多句子. 比较训练时间和结果.</li>
<li>如果您使用的翻译文件对中有两个相同的短语(<code>I am test \t I am test</code>), 您可以使用它作为自动编码器.尝试这个: - 训练自编码器 - 只保存编码器网络 - 从那里训练一个新的解码器进行翻译</li>
</ul>
<p><strong>Total running time of the script:</strong> ( 0 minutes 0.000 seconds)</p>
<p><a href="../_downloads/seq2seq_translation_tutorial.py"><code>Download Python source code: seq2seq_translation_tutorial.py</code></a><a href="../_downloads/seq2seq_translation_tutorial.ipynb"><code>Download Jupyter notebook: seq2seq_translation_tutorial.ipynb</code></a></p>
<p><a href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
                
                  
                
              
              
                


              

              <hr/>
              <div align="center">
                  <p><a href="http://www.apachecn.org/" target="_blank"><font face="KaiTi" size="6" color="red">我们一直在努力</font></a><p>
                  <p><a href="https://github.com/apachecn/pytorch-doc-zh/" target="_blank">apachecn/pytorch-doc-zh</a></p>
                  <p><iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&repo=pytorch-doc-zh&type=watch&count=true&v=2" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
                  <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&repo=pytorch-doc-zh&type=star&count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
                  <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&repo=pytorch-doc-zh&type=fork&count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
                  <a target="_blank" href="//shang.qq.com/wpa/qunwpa?idkey=bcee938030cc9e1552deb3bd9617bbbf62d3ec1647e4b60d9cd6b6e8f78ddc03"><img border="0" src="//pub.idqqimg.com/wpa/images/group.png" alt="ML | ApacheCN" title="ML | ApacheCN"></a></p>
                  <div style="text-align:center;margin:0 0 10.5px;"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
                        <ins class="adsbygoogle"
                             style="display:inline-block;width:728px;height:90px"
                             data-ad-client="ca-pub-3565452474788507"
                             data-ad-slot="2543897000"></ins>
                        <script>
                        (adsbygoogle = window.adsbygoogle || []).push({});
                        </script></div>
              </div>

              <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
              <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
              <div id="gitalk-container" class="container-fluid"></div>
              <script type="text/javascript">
                  var gitalk = new Gitalk({
                  clientID: 'f27b87eb424ba43df978',
                  clientSecret: '9b3482a495c5257a1d269d8108b9bfd71f048c3c',
                  repo: 'pytorch-doc-zh',
                  owner: 'apachecn',
                  admin: ['jiangzhonglian'],
                  id: md5(location.pathname),
                  distractionFreeMode: false
                  })
                  gitalk.render('gitalk-container')
              </script>
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../32/" title="基与字符级RNN（Char-RNN）的人名生成" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                基与字符级RNN（Char-RNN）的人名生成
              </span>
            </div>
          </a>
        
        
          <a href="../34/" title="强化学习（DQN）教程" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                强化学习（DQN）教程
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.583bbe55.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>